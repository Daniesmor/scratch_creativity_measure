{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8875ad-8161-457c-8637-4a2c7a7db72a",
   "metadata": {},
   "source": [
    "# Embeddings from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "513f92f9-b2a5-415e-bd80-ad1a9009f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c088a391-b7ee-49df-8b30-41e79a173c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'La inteligencia artificial es la hostia',\n",
    "    'El procesamiento de lenguaje natural es una rama del aprendizaje profundo',\n",
    "    \"Me encanta estudar inteligencia artifical\",\n",
    "    \"Las películas de inteligencia artificial me encantan\",\n",
    "    \"El arendizaje profundo es una subcategoría de la inteligencia artificial\",\n",
    "    \"Los embeddings de palabras capturan semántica\",\n",
    "    \"PyTorch es una herramienta para aprendiaje profundo e inteligencia artificial\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f28febf-d550-4c14-b9aa-d6bf83a4b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramData(Dataset):\n",
    "    def __init__(self, corpus, window_sz= 2):\n",
    "        super().__init__\n",
    "        self.corpus = corpus\n",
    "        self.window = window_sz\n",
    "        self.vocab = list(set(token.lower() for sentence in self.corpus for token in sentence.split())) # set elimina dups y no mantiene el orden\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.data = self.gen_dataset()\n",
    "\n",
    "    def gen_dataset(self):\n",
    "        # Metod for enventanado\n",
    "        data = []\n",
    "        for sentence in self.corpus:\n",
    "            text = sentence.lower().split()\n",
    "            print(text)\n",
    "            for center_idx, center_word in enumerate(text):\n",
    "                for offset in range(-self.window, self.window +1):\n",
    "                    context_idx = center_idx + offset\n",
    "                    if context_idx < 0 or context_idx >= len(text) or context_idx == center_idx: continue\n",
    "                    context_word = text[context_idx]\n",
    "                    data.append((self.word2idx[center_word], self.word2idx[context_word]))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e7d5453-d0d3-4c2e-ac35-212b44ef5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_sz, embed_sz):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Linear(vocab_sz, embed_sz, bias = False)\n",
    "        self.output_Layer = nn.Linear(embed_sz, vocab_sz)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output_layer(self.embed_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367eeba3-b300-4a66-a238-246cc52b09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_skipgrad(model, loss_function, optimizer, data_loader, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for center, context in data_loader:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "152c5560-09a2-419a-a681-ed15219431c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la', 'inteligencia', 'artificial', 'es', 'la', 'hostia']\n",
      "['el', 'procesamiento', 'de', 'lenguaje', 'natural', 'es', 'una', 'rama', 'del', 'aprendizaje', 'profundo']\n",
      "['me', 'encanta', 'estudar', 'inteligencia', 'artifical']\n",
      "['las', 'películas', 'de', 'inteligencia', 'artificial', 'me', 'encantan']\n",
      "['el', 'arendizaje', 'profundo', 'es', 'una', 'subcategoría', 'de', 'la', 'inteligencia', 'artificial']\n",
      "['los', 'embeddings', 'de', 'palabras', 'capturan', 'semántica']\n",
      "['pytorch', 'es', 'una', 'herramienta', 'para', 'aprendiaje', 'profundo', 'e', 'inteligencia', 'artificial']\n",
      "la inteligencia\n",
      "la artificial\n",
      "inteligencia la\n",
      "inteligencia artificial\n",
      "inteligencia es\n",
      "artificial la\n",
      "artificial inteligencia\n",
      "artificial es\n",
      "artificial la\n",
      "es inteligencia\n",
      "es artificial\n",
      "es la\n",
      "es hostia\n",
      "la artificial\n",
      "la es\n",
      "la hostia\n",
      "hostia es\n",
      "hostia la\n",
      "el procesamiento\n",
      "el de\n",
      "procesamiento el\n",
      "procesamiento de\n",
      "procesamiento lenguaje\n",
      "de el\n",
      "de procesamiento\n",
      "de lenguaje\n",
      "de natural\n",
      "lenguaje procesamiento\n",
      "lenguaje de\n",
      "lenguaje natural\n",
      "lenguaje es\n",
      "natural de\n",
      "natural lenguaje\n",
      "natural es\n",
      "natural una\n",
      "es lenguaje\n",
      "es natural\n",
      "es una\n",
      "es rama\n",
      "una natural\n",
      "una es\n",
      "una rama\n",
      "una del\n",
      "rama es\n",
      "rama una\n",
      "rama del\n",
      "rama aprendizaje\n",
      "del una\n",
      "del rama\n",
      "del aprendizaje\n",
      "del profundo\n",
      "aprendizaje rama\n",
      "aprendizaje del\n",
      "aprendizaje profundo\n",
      "profundo del\n",
      "profundo aprendizaje\n",
      "me encanta\n",
      "me estudar\n",
      "encanta me\n",
      "encanta estudar\n",
      "encanta inteligencia\n",
      "estudar me\n",
      "estudar encanta\n",
      "estudar inteligencia\n",
      "estudar artifical\n",
      "inteligencia encanta\n",
      "inteligencia estudar\n",
      "inteligencia artifical\n",
      "artifical estudar\n",
      "artifical inteligencia\n",
      "las películas\n",
      "las de\n",
      "películas las\n",
      "películas de\n",
      "películas inteligencia\n",
      "de las\n",
      "de películas\n",
      "de inteligencia\n",
      "de artificial\n",
      "inteligencia películas\n",
      "inteligencia de\n",
      "inteligencia artificial\n",
      "inteligencia me\n",
      "artificial de\n",
      "artificial inteligencia\n",
      "artificial me\n",
      "artificial encantan\n",
      "me inteligencia\n",
      "me artificial\n",
      "me encantan\n",
      "encantan artificial\n",
      "encantan me\n",
      "el arendizaje\n",
      "el profundo\n",
      "arendizaje el\n",
      "arendizaje profundo\n",
      "arendizaje es\n",
      "profundo el\n",
      "profundo arendizaje\n",
      "profundo es\n",
      "profundo una\n",
      "es arendizaje\n",
      "es profundo\n",
      "es una\n",
      "es subcategoría\n",
      "una profundo\n",
      "una es\n",
      "una subcategoría\n",
      "una de\n",
      "subcategoría es\n",
      "subcategoría una\n",
      "subcategoría de\n",
      "subcategoría la\n",
      "de una\n",
      "de subcategoría\n",
      "de la\n",
      "de inteligencia\n",
      "la subcategoría\n",
      "la de\n",
      "la inteligencia\n",
      "la artificial\n",
      "inteligencia de\n",
      "inteligencia la\n",
      "inteligencia artificial\n",
      "artificial la\n",
      "artificial inteligencia\n",
      "los embeddings\n",
      "los de\n",
      "embeddings los\n",
      "embeddings de\n",
      "embeddings palabras\n",
      "de los\n",
      "de embeddings\n",
      "de palabras\n",
      "de capturan\n",
      "palabras embeddings\n",
      "palabras de\n",
      "palabras capturan\n",
      "palabras semántica\n",
      "capturan de\n",
      "capturan palabras\n",
      "capturan semántica\n",
      "semántica palabras\n",
      "semántica capturan\n",
      "pytorch es\n",
      "pytorch una\n",
      "es pytorch\n",
      "es una\n",
      "es herramienta\n",
      "una pytorch\n",
      "una es\n",
      "una herramienta\n",
      "una para\n",
      "herramienta es\n",
      "herramienta una\n",
      "herramienta para\n",
      "herramienta aprendiaje\n",
      "para una\n",
      "para herramienta\n",
      "para aprendiaje\n",
      "para profundo\n",
      "aprendiaje herramienta\n",
      "aprendiaje para\n",
      "aprendiaje profundo\n",
      "aprendiaje e\n",
      "profundo para\n",
      "profundo aprendiaje\n",
      "profundo e\n",
      "profundo inteligencia\n",
      "e aprendiaje\n",
      "e profundo\n",
      "e inteligencia\n",
      "e artificial\n",
      "inteligencia profundo\n",
      "inteligencia e\n",
      "inteligencia artificial\n",
      "artificial e\n",
      "artificial inteligencia\n",
      "(22, 5)\n"
     ]
    }
   ],
   "source": [
    "dataset = SkipGramData(sentences)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "model = SkipGram(len(dataset.vocab), embed_sz=300)\n",
    "for center_idx, context_idx in dataset.data:\n",
    "    print(dataset.idx2word[center_idx],dataset.idx2word[context_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2633e5-6236-4a93-8d7b-0de8cdcd48d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
